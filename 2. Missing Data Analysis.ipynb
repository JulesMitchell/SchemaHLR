{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint 2 - Missing Data Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update and Checkpoint\n",
    "1. The data was analysed in SPSS to evaluate the missing nature of the data with the Little MCAR's\n",
    "2. The total of missing data were:\n",
    "    2a) Cases = 175 (11.1%)\n",
    "    2b) Questions = 71 (51%)\n",
    "    2c) Responses =\n",
    "3. Little MCAR's test indicated data are not MNAR: (provide statistics) = X2 [1762] = 2084.73, p < 0.001).\n",
    "4. Therefore, as greater than 5% cases were missing data, multiple imputation performed in python.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint 3 - Multiple Imputation\n",
    "\n",
    "1. Using the miceforest package, multiple imputation of missing data was performed. \n",
    "2. A total of 5 iterations are performed, with results pooled automatically. \n",
    "3. Imputed values are checked visually and with descriptive statistics to ensure appropriate range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#check and set working directory\n",
    "cwd = os.getcwd()  # Get the current working directory (cwd)\n",
    "files = os.listdir(cwd)  # Get all the files in that directory\n",
    "print(\"Files in %r: %s\" % (cwd, files))\n",
    "print(cwd+ \"\\\\\" +files[0])\n",
    "\n",
    "os.chdir('c:\\\\Users\\\\j_m289\\\\Pictures\\\\PHD\\\\15. Data Analysis\\HMR\\Raw')  # Provide the new path here\n",
    "\n",
    "#try to use relative path for files (tied to directory and nesting within folders)\n",
    "path = \"/Users/j_m289\\Pictures\\PHD\\15. Data Analysis\\HMR\\Raw\"\n",
    "  \n",
    "start = \"/Users/j_m289\"\n",
    "\n",
    "relative_path = os.path.relpath(path, start)\n",
    "\n",
    "#Load packages\n",
    "#pandas for data frame management and descriptives (in addition to numpy)\n",
    "#scipy for HMR model\n",
    "#seaborn for visualisation (MATPLOTLIB also)\n",
    "\n",
    "import pandas as pd\n",
    "import missingno as mn\n",
    "import miceforest as mf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Imputation with MICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load raw_clean dataset and check missing data\n",
    "missing_values =['n/a', 'na', '9999'] # missing values list is added so that pandas can read these\n",
    "\n",
    "df_clean = pd.read_excel('raw_clean.xlsx', na_values = missing_values, engine='openpyxl')   # Load file and set missing values\n",
    "df_clean.drop(columns= ['Unnamed: 0'], inplace=True)  # drop unnecessary column\n",
    "\n",
    "for column in df_clean:     \n",
    "    # Select column contents by column\n",
    "    # name using [] operator\n",
    "    columnSeriesObj = df_clean[column]\n",
    "    print('Column Name : ', column)\n",
    "    print('Column Contents : ', df_clean[column].isnull().sum()) #check missing values per column\n",
    "\n",
    "#assign columns to values to append to completed dataset in last step\n",
    "df_MH_diag = df_clean['MH_Diag_type']\n",
    "df_ED_sub = df_clean['ED_subtype']\n",
    "df_pastED_sub = df_clean['past_ED_subtype']\n",
    "\n",
    "#columns that contain strings are dropped as they prevent multiple imputation function\n",
    "df_clean = df_clean.drop(columns= ['MH_Diag_type','ED_subtype','past_ED_subtype'], inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert columns to floats\n",
    "for col in df_clean:\n",
    "    df_clean[col] = df_clean[col].astype('float64')\n",
    "\n",
    "df_clean.dtypes.value_counts()\n",
    "\n",
    "#Run multiple imputation with mice (random state = 1)\n",
    "kernel = mf.ImputationKernel(\n",
    "  df_clean,\n",
    "  datasets=4,\n",
    "  save_all_iterations=True,\n",
    "  random_state=1\n",
    ")\n",
    "# Run the MICE algorithm for 5 iterations on each of the datasets\n",
    "kernel.mice(5)\n",
    "\n",
    "# Printing the kernel will show you some high level information.\n",
    "print(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputed datasets assigned to completed dataset and missing data checks\n",
    "completed_dataset = kernel.complete_data(dataset=2)\n",
    "#check missing values\n",
    "print(completed_dataset.isnull().sum(0))\n",
    "# visual inspection\n",
    "display(completed_dataset) \n",
    "kernel.plot_imputed_distributions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export to 'completedDataset.xlsx' file to the 'clean' folder\n",
    "completed_dataset.drop(columns= ['Unnamed: 0', 'Unnamed: 0.1'], inplace=True)  # drop unnecessary column\n",
    "os.chdir('c:\\\\Users\\\\j_m289\\\\Pictures\\\\PHD\\\\15. Data Analysis\\HMR\\Clean')  # Provide the new path here\n",
    "completed_dataset.to_excel('completedDataset.xlsx', index=True) #re-save dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "29e547e41c87afeb9696b6464f69a6550dcc235cb1c66aa90cdc209960d5915f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
